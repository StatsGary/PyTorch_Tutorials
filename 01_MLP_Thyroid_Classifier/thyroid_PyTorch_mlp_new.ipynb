{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import vstack\n",
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, average_precision_score\n",
    "from sklearn.metrics import confusion_matrix, recall_score, f1_score\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Sigmoid\n",
    "from torch.nn import Module\n",
    "from torch.optim import SGD\n",
    "from torch.nn import BCELoss\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "from torch.nn.init import xavier_uniform_\n",
    "import time\n",
    "import copy\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original Thyroid data frame contains 27 columns\n",
      "The thyroid X data frame contains 26 columns\n"
     ]
    }
   ],
   "source": [
    "\n",
    "thyroid = pd.read_csv('data/thyroid_new.csv').drop('ID', axis=1)\n",
    "NUM_INPUTS = len(thyroid.columns)\n",
    "print(f'The original Thyroid data frame contains {len(thyroid.columns)} columns')\n",
    "y_label = thyroid['ThryroidClass'] \n",
    "# Preprocess and get rid of na\n",
    "thyroid = thyroid.dropna()\n",
    "\n",
    "# Scale X data\n",
    "X = thyroid.drop('ThryroidClass', axis=1)\n",
    "\n",
    "#thyroid.ThryroidClass\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = pd.DataFrame(scaler.transform(X))\n",
    "print(f'The thyroid X data frame contains {len(X.columns)} columns')\n",
    "Y = pd.Series(y_label)\n",
    "thyroid = pd.concat([X,Y], axis=1)\n",
    "thyroid = thyroid.dropna()\n",
    "thyroid.to_csv('thyroid_raw.csv', header=None, index=None)\n",
    "\n",
    "DATASET_SIZE = len(thyroid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Replicate data loader process\n",
    "x = thyroid.values[:, :-1]\n",
    "y = thyroid.values[:,-1]\n",
    "x = x.astype('float32')\n",
    "y_encoded = LabelEncoder().fit_transform(y)\n",
    "y_encoded = y_encoded.astype('float32')\n",
    "y_arrayed = y_encoded.reshape((len(y_encoded), 1))\n",
    "print(y_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom CSVDataset loader\n",
    "\n",
    "class ThryoidCSVDataset(Dataset):\n",
    "    #Constructor for initially loading\n",
    "    def __init__(self,path):\n",
    "        df = read_csv(path, header=None)\n",
    "        # Store the inputs and outputs\n",
    "        self.X = df.values[:, :-1]\n",
    "        self.y = df.values[:, -1] #Assuming your outcome variable is in the first column\n",
    "        self.X = self.X.astype('float32')\n",
    "        # Label encode the target as values 1 and 0 or sick and not sick\n",
    "        self.y = LabelEncoder().fit_transform(self.y)\n",
    "        self.y = self.y.astype('float32')\n",
    "        self.y = self.y.reshape((len(self.y), 1))\n",
    "\n",
    "    # Get the number of rows in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    # Get a row at an index\n",
    "    def __getitem__(self,idx):\n",
    "        return [self.X[idx], self.y[idx]]\n",
    "\n",
    "    # Create custom class method - instead of dunder methods\n",
    "    def split_data(self, split_ratio=0.2):\n",
    "        test_size = round(split_ratio * len(self.X))\n",
    "        train_size = len(self.X) - test_size\n",
    "        return random_split(self, [train_size, test_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "class ThyroidMLP(Module):\n",
    "    def __init__(self, n_inputs):\n",
    "        super(ThyroidMLP, self).__init__()\n",
    "        # First hidden layer\n",
    "        self.hidden1 = Linear(n_inputs, 20)\n",
    "        kaiming_uniform_(self.hidden1.weight, nonlinearity='relu')\n",
    "        self.act1 = ReLU()\n",
    "        # Second hidden layer\n",
    "        self.hidden2 = Linear(20, 10)\n",
    "        kaiming_uniform_(self.hidden2.weight, nonlinearity='relu')\n",
    "        self.act2 = ReLU()\n",
    "        # Third hidden layer\n",
    "        self.hidden3 = Linear(10,1)\n",
    "        xavier_uniform_(self.hidden3.weight)\n",
    "        self.act3 = Sigmoid()\n",
    "\n",
    "    def forward(self, X):\n",
    "        #Input to the first hidden layer\n",
    "        X = self.hidden1(X)\n",
    "        X = self.act1(X)\n",
    "        # Second hidden layer\n",
    "        X = self.hidden2(X)\n",
    "        X = self.act2(X)\n",
    "        # Third hidden layer\n",
    "        X = self.hidden3(X)\n",
    "        X = self.act3(X)\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_thyroid_dataset(path):\n",
    "    dataset = ThryoidCSVDataset(path)\n",
    "    train, test = dataset.split_data(split_ratio=0.1)\n",
    "    # Prepare data loaders\n",
    "    train_len = len(train)\n",
    "    train_dl = DataLoader(train, batch_size=32, shuffle=True)\n",
    "    test_dl = DataLoader(test, batch_size=1024, shuffle=False)\n",
    "    return train_dl, test_dl, train_len\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training loop based off our custom class\n",
    "def train_model(train_dl, model, epochs=100, lr=0.01, momentum=0.9, save_path='thyroid_best_model.pth'):\n",
    "    # Define your optimisation function for reducing loss when weights are calculated \n",
    "    # and propogated through the network\n",
    "    start = time.time()\n",
    "    total = 0\n",
    "    criterion = BCELoss()\n",
    "    optimizer = SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    loss = 0.0\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        correct = 0\n",
    "        print('Epoch {}/{}'.format(epoch+1, epochs))\n",
    "        print('-' * 10)\n",
    "        model.train()\n",
    "        # Iterate through training data loader\n",
    "        for i, (inputs, targets) in enumerate(train_dl):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs.data,1) #Get the class labels\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total += targets.size(0)\n",
    "            correct += (preds == targets).sum().item()\n",
    "            torch.save(model, save_path)\n",
    "        acc = correct / total\n",
    "        print(f'Current accuracy is: {acc}')\n",
    "    time_delta = time.time() - start\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_delta // 60, time_delta % 60\n",
    "    ))\n",
    "    \n",
    "    return model\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def evaluate_model(test_dl, model, beta=1.0):\n",
    "    preds = []\n",
    "    actuals = []\n",
    "\n",
    "    for (i, (inputs, targets)) in enumerate(test_dl):\n",
    "        #Evaluate the model on the test set\n",
    "        yhat = model(inputs)\n",
    "        #Retrieve a numpy weights array\n",
    "        yhat = yhat.detach().numpy()\n",
    "        # Extract the weights using detach to get the numerical values in an ndarray, instead of tensor\n",
    "        #https://www.tutorialspoint.com/how-to-convert-a-pytorch-tensor-with-gradient-to-a-numpy-array\n",
    "        actual = targets.numpy()\n",
    "        actual = actual.reshape((len(actual), 1))\n",
    "        # Round to get the class value i.e. sick vs not sick\n",
    "        yhat = yhat.round()\n",
    "        # Store the predictions in the empty lists initialised at the start of the class\n",
    "        preds.append(yhat)\n",
    "        actuals.append(actual)\n",
    "    \n",
    "    # Stack the predictions and actual arrays vertically\n",
    "    preds, actuals = vstack(preds), vstack(actuals)\n",
    "    #Calculate metrics\n",
    "    cm = confusion_matrix(actuals, preds)\n",
    "    # Get descriptions of tp, tn, fp, fn\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    total = sum(cm.ravel())\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(actuals, preds),\n",
    "        'AU_ROC': roc_auc_score(actuals, preds),\n",
    "        'f1_score': f1_score(actuals, preds),\n",
    "        'average_precision_score': average_precision_score(actuals, preds),\n",
    "        'f_beta': ((1+beta**2) * precision_score(actuals, preds) * recall_score(actuals, preds)) / (beta**2 * precision_score(actuals, preds) + recall_score(actuals, preds)),\n",
    "        'matthews_correlation_coefficient': (tp*tn - fp*fn) / math.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)),\n",
    "        'precision': precision_score(actuals, preds),\n",
    "        'recall': recall_score(actuals, preds),\n",
    "        'true_positive_rate_TPR':recall_score(actuals, preds),\n",
    "        'false_positive_rate_FPR':fp / (fp + tn) ,\n",
    "        'false_discovery_rate': fp / (fp +tp),\n",
    "        'false_negative_rate': fn / (fn + tp) ,\n",
    "        'negative_predictive_value': tn / (tn+fn),\n",
    "        'misclassification_error_rate': (fp+fn)/total ,\n",
    "        'sensitivity': tp / (tp + fn),\n",
    "        'specificity': tn / (tn + fp),\n",
    "        #'confusion_matrix': confusion_matrix(actuals, preds), \n",
    "        'TP': tp,\n",
    "        'FP': fp, \n",
    "        'FN': fn, \n",
    "        'TN': tn\n",
    "    }\n",
    "    return metrics, preds, actuals\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prediction routine\n",
    "def predict(row, model):\n",
    "    row = Tensor([row])\n",
    "    yhat = model(row)\n",
    "    # Get numpy array\n",
    "    yhat = yhat.detach().numpy()\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, test_dl, train_len = prepare_thyroid_dataset('https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv')\n",
    "#train_dl, test_dl, train_len = prepare_thyroid_dataset('https://raw.githubusercontent.com/StatsGary/Data/main/thyroid_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316 35\n",
      "<torch.utils.data.dataset.Subset object at 0x7ff7dc526e50>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "316"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_dl.dataset), len(test_dl.dataset))\n",
    "print(train_dl.dataset)\n",
    "train_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "----------\n",
      "Current accuracy is: 11.544303797468354\n",
      "Epoch 2/100\n",
      "----------\n",
      "Current accuracy is: 5.7594936708860756\n",
      "Epoch 3/100\n",
      "----------\n",
      "Current accuracy is: 3.8438818565400843\n",
      "Epoch 4/100\n",
      "----------\n",
      "Current accuracy is: 2.8892405063291138\n",
      "Epoch 5/100\n",
      "----------\n",
      "Current accuracy is: 2.30126582278481\n",
      "Epoch 6/100\n",
      "----------\n",
      "Current accuracy is: 1.9282700421940928\n",
      "Epoch 7/100\n",
      "----------\n",
      "Current accuracy is: 1.6491862567811935\n",
      "Epoch 8/100\n",
      "----------\n",
      "Current accuracy is: 1.4414556962025316\n",
      "Epoch 9/100\n",
      "----------\n",
      "Current accuracy is: 1.279887482419128\n",
      "Epoch 10/100\n",
      "----------\n",
      "Current accuracy is: 1.1544303797468354\n",
      "Epoch 11/100\n",
      "----------\n",
      "Current accuracy is: 1.046029919447641\n",
      "Epoch 12/100\n",
      "----------\n",
      "Current accuracy is: 0.9578059071729957\n",
      "Epoch 13/100\n",
      "----------\n",
      "Current accuracy is: 0.8880233690360273\n",
      "Epoch 14/100\n",
      "----------\n",
      "Current accuracy is: 0.8227848101265823\n",
      "Epoch 15/100\n",
      "----------\n",
      "Current accuracy is: 0.770464135021097\n",
      "Epoch 16/100\n",
      "----------\n",
      "Current accuracy is: 0.7191455696202531\n",
      "Epoch 17/100\n",
      "----------\n",
      "Current accuracy is: 0.6753536857781087\n",
      "Epoch 18/100\n",
      "----------\n",
      "Current accuracy is: 0.6413502109704642\n",
      "Epoch 19/100\n",
      "----------\n",
      "Current accuracy is: 0.6062624916722186\n",
      "Epoch 20/100\n",
      "----------\n",
      "Current accuracy is: 0.5746835443037974\n",
      "Epoch 21/100\n",
      "----------\n",
      "Current accuracy is: 0.5473176612417119\n",
      "Epoch 22/100\n",
      "----------\n",
      "Current accuracy is: 0.523590333716916\n",
      "Epoch 23/100\n",
      "----------\n",
      "Current accuracy is: 0.49752339020363234\n",
      "Epoch 24/100\n",
      "----------\n",
      "Current accuracy is: 0.47732067510548526\n",
      "Epoch 25/100\n",
      "----------\n",
      "Current accuracy is: 0.45772151898734176\n",
      "Epoch 26/100\n",
      "----------\n",
      "Current accuracy is: 0.4425511197663096\n",
      "Epoch 27/100\n",
      "----------\n",
      "Current accuracy is: 0.426629160806376\n",
      "Epoch 28/100\n",
      "----------\n",
      "Current accuracy is: 0.41094032549728754\n",
      "Epoch 29/100\n",
      "----------\n",
      "Current accuracy is: 0.3998254037538193\n",
      "Epoch 30/100\n",
      "----------\n",
      "Current accuracy is: 0.3822784810126582\n",
      "Epoch 31/100\n",
      "----------\n",
      "Current accuracy is: 0.37117190690077584\n",
      "Epoch 32/100\n",
      "----------\n",
      "Current accuracy is: 0.35957278481012656\n",
      "Epoch 33/100\n",
      "----------\n",
      "Current accuracy is: 0.34829305715381664\n",
      "Epoch 34/100\n",
      "----------\n",
      "Current accuracy is: 0.33916604616530155\n",
      "Epoch 35/100\n",
      "----------\n",
      "Current accuracy is: 0.3301989150090416\n",
      "Epoch 36/100\n",
      "----------\n",
      "Current accuracy is: 0.32032348804500704\n",
      "Epoch 37/100\n",
      "----------\n",
      "Current accuracy is: 0.31166609647622306\n",
      "Epoch 38/100\n",
      "----------\n",
      "Current accuracy is: 0.3034643570952698\n",
      "Epoch 39/100\n",
      "----------\n",
      "Current accuracy is: 0.29568321973385264\n",
      "Epoch 40/100\n",
      "----------\n",
      "Current accuracy is: 0.2892405063291139\n",
      "Epoch 41/100\n",
      "----------\n",
      "Current accuracy is: 0.28125964803951836\n",
      "Epoch 42/100\n",
      "----------\n",
      "Current accuracy is: 0.2739602169981917\n",
      "Epoch 43/100\n",
      "----------\n",
      "Current accuracy is: 0.26788342655284075\n",
      "Epoch 44/100\n",
      "----------\n",
      "Current accuracy is: 0.2612197928653625\n",
      "Epoch 45/100\n",
      "----------\n",
      "Current accuracy is: 0.25625879043600563\n",
      "Epoch 46/100\n",
      "----------\n",
      "Current accuracy is: 0.25123830489818383\n",
      "Epoch 47/100\n",
      "----------\n",
      "Current accuracy is: 0.2458928090492863\n",
      "Epoch 48/100\n",
      "----------\n",
      "Current accuracy is: 0.24024261603375527\n",
      "Epoch 49/100\n",
      "----------\n",
      "Current accuracy is: 0.23637303022474812\n",
      "Epoch 50/100\n",
      "----------\n",
      "Current accuracy is: 0.22936708860759494\n",
      "Epoch 51/100\n",
      "----------\n",
      "Current accuracy is: 0.22536609580541078\n",
      "Epoch 52/100\n",
      "----------\n",
      "Current accuracy is: 0.22200584225900682\n",
      "Epoch 53/100\n",
      "----------\n",
      "Current accuracy is: 0.21638404585622165\n",
      "Epoch 54/100\n",
      "----------\n",
      "Current accuracy is: 0.21284575714955462\n",
      "Epoch 55/100\n",
      "----------\n",
      "Current accuracy is: 0.21012658227848102\n",
      "Epoch 56/100\n",
      "----------\n",
      "Current accuracy is: 0.20501808318264014\n",
      "Epoch 57/100\n",
      "----------\n",
      "Current accuracy is: 0.20186542305129915\n",
      "Epoch 58/100\n",
      "----------\n",
      "Current accuracy is: 0.19751200349192494\n",
      "Epoch 59/100\n",
      "----------\n",
      "Current accuracy is: 0.19523707358935852\n",
      "Epoch 60/100\n",
      "----------\n",
      "Current accuracy is: 0.19177215189873417\n",
      "Epoch 61/100\n",
      "----------\n",
      "Current accuracy is: 0.18862834612990248\n",
      "Epoch 62/100\n",
      "----------\n",
      "Current accuracy is: 0.18599428338097182\n",
      "Epoch 63/100\n",
      "----------\n",
      "Current accuracy is: 0.1828410689170183\n",
      "Epoch 64/100\n",
      "----------\n",
      "Current accuracy is: 0.17998417721518986\n",
      "Epoch 65/100\n",
      "----------\n",
      "Current accuracy is: 0.17702044790652385\n",
      "Epoch 66/100\n",
      "----------\n",
      "Current accuracy is: 0.17472190257000383\n",
      "Epoch 67/100\n",
      "----------\n",
      "Current accuracy is: 0.17230304175325903\n",
      "Epoch 68/100\n",
      "----------\n",
      "Current accuracy is: 0.16958302308265077\n",
      "Epoch 69/100\n",
      "----------\n",
      "Current accuracy is: 0.16657494037791232\n",
      "Epoch 70/100\n",
      "----------\n",
      "Current accuracy is: 0.1650994575045208\n",
      "Epoch 71/100\n",
      "----------\n",
      "Current accuracy is: 0.16223925833481903\n",
      "Epoch 72/100\n",
      "----------\n",
      "Current accuracy is: 0.16033755274261605\n",
      "Epoch 73/100\n",
      "----------\n",
      "Current accuracy is: 0.1577943471475637\n",
      "Epoch 74/100\n",
      "----------\n",
      "Current accuracy is: 0.15480670543961683\n",
      "Epoch 75/100\n",
      "----------\n",
      "Current accuracy is: 0.15358649789029535\n",
      "Epoch 76/100\n",
      "----------\n",
      "Current accuracy is: 0.1517321785476349\n",
      "Epoch 77/100\n",
      "----------\n",
      "Current accuracy is: 0.1494328456353773\n",
      "Epoch 78/100\n",
      "----------\n",
      "Current accuracy is: 0.14767932489451477\n",
      "Epoch 79/100\n",
      "----------\n",
      "Current accuracy is: 0.14580996635154622\n",
      "Epoch 80/100\n",
      "----------\n",
      "Current accuracy is: 0.14382911392405062\n",
      "Epoch 81/100\n",
      "----------\n",
      "Current accuracy is: 0.14252226910454757\n",
      "Epoch 82/100\n",
      "----------\n",
      "Current accuracy is: 0.14109292991664094\n",
      "Epoch 83/100\n",
      "----------\n",
      "Current accuracy is: 0.1390879975598597\n",
      "Epoch 84/100\n",
      "----------\n",
      "Current accuracy is: 0.1372814948764316\n",
      "Epoch 85/100\n",
      "----------\n",
      "Current accuracy is: 0.13581533879374535\n",
      "Epoch 86/100\n",
      "----------\n",
      "Current accuracy is: 0.1332057697968796\n",
      "Epoch 87/100\n",
      "----------\n",
      "Current accuracy is: 0.13182016586643386\n",
      "Epoch 88/100\n",
      "----------\n",
      "Current accuracy is: 0.130897583429229\n",
      "Epoch 89/100\n",
      "----------\n",
      "Current accuracy is: 0.12900014222727918\n",
      "Epoch 90/100\n",
      "----------\n",
      "Current accuracy is: 0.12784810126582277\n",
      "Epoch 91/100\n",
      "----------\n",
      "Current accuracy is: 0.12672137988593685\n",
      "Epoch 92/100\n",
      "----------\n",
      "Current accuracy is: 0.12520638414969731\n",
      "Epoch 93/100\n",
      "----------\n",
      "Current accuracy is: 0.12426840887437049\n",
      "Epoch 94/100\n",
      "----------\n",
      "Current accuracy is: 0.12213843253433881\n",
      "Epoch 95/100\n",
      "----------\n",
      "Current accuracy is: 0.12138574283810792\n",
      "Epoch 96/100\n",
      "----------\n",
      "Current accuracy is: 0.11933016877637131\n",
      "Epoch 97/100\n",
      "----------\n",
      "Current accuracy is: 0.11836095523946236\n",
      "Epoch 98/100\n",
      "----------\n",
      "Current accuracy is: 0.11766985275122707\n",
      "Epoch 99/100\n",
      "----------\n",
      "Current accuracy is: 0.11558624216852065\n",
      "Epoch 100/100\n",
      "----------\n",
      "Current accuracy is: 0.1150632911392405\n",
      "Training complete in 0m 2s\n",
      "{'accuracy': 0.9714285714285714, 'AU_ROC': 0.9791666666666667, 'f1_score': 0.9787234042553191, 'average_precision_score': 0.986904761904762, 'f_beta': 0.9598715890850723, 'matthews_correlation_coefficient': 0.9372684899334994, 'precision': 1.0, 'recall': 0.9583333333333334, 'true_positive_rate_TPR': 0.9583333333333334, 'false_positive_rate_FPR': 0.0, 'false_discovery_rate': 0.0, 'false_negative_rate': 0.041666666666666664, 'negative_predictive_value': 0.9166666666666666, 'misclassification_error_rate': 0.02857142857142857, 'sensitivity': 0.9583333333333334, 'specificity': 1.0, 'TP': 23, 'FP': 0, 'FN': 1, 'TN': 11}\n"
     ]
    }
   ],
   "source": [
    "# Specify the number of input dimensions\n",
    "model = ThyroidMLP(34)\n",
    "# Train the model\n",
    "train_model(train_dl, model, save_path='data/thyroid_model.pth')\n",
    "# Evaluate the model\n",
    "results = evaluate_model(test_dl, model, beta=5)\n",
    "model_metrics = results[0]\n",
    "preds = results[1]\n",
    "actuals_gt_labesl = results[2]\n",
    "print(model_metrics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "92c9f56e7a4fd721f9baef38bcdf25b30d0e78c89f6fb2c3207e6b27a13e62be"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('transformers-robots')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
