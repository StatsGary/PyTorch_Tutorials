{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import vstack\n",
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Sigmoid\n",
    "from torch.nn import Module\n",
    "from torch.optim import SGD\n",
    "from torch.nn import BCELoss\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "from torch.nn.init import xavier_uniform_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "thyroid = pd.read_csv('data/thyroid_new.csv').drop('ID', axis=1)\n",
    "y_label = (thyroid['ThryroidClass']=='sick').astype(int)\n",
    "thyroid['ThryroidClass'] = y_label\n",
    "# Preprocess and get rid of na\n",
    "thyroid = thyroid.dropna()\n",
    "\n",
    "# Scale X data\n",
    "X = thyroid.drop('ThryroidClass', axis=1)\n",
    "\n",
    "#thyroid.ThryroidClass\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = pd.DataFrame(scaler.transform(X))\n",
    "Y = pd.Series(y_label)\n",
    "thyroid = pd.concat([Y,X], axis=1)\n",
    "thyroid = thyroid.dropna()\n",
    "thyroid.to_csv('data/final.csv',header=None, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom CSVDataset loader\n",
    "# https://machinelearningmastery.com/pytorch-tutorial-develop-deep-learning-models/\n",
    "class ThryoidCSVDataset(Dataset):\n",
    "    #Constructor for initially loading\n",
    "    def __init__(self,path):\n",
    "        df = read_csv(path, header=None)\n",
    "        # Store the inputs and outputs\n",
    "        self.X = df.values[:, :-1]\n",
    "        self.y = df.values[:, -1] #Assuming your outcome variable is in the first column\n",
    "        self.X = self.X.astype('float32')\n",
    "        # Label encode the target as values 1 and 0 or sick and not sick\n",
    "        self.y = LabelEncoder().fit_transform(self.y)\n",
    "        self.y = self.y.astype('float32')\n",
    "        self.y = self.y.reshape((len(self.y), 1))\n",
    "\n",
    "    # Get the number of rows in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    # Get a row at an index\n",
    "    def __getitem__(self,idx):\n",
    "        return [self.X[idx], self.y[idx]]\n",
    "\n",
    "    # Create custom class method - instead of dunder methods\n",
    "    def split_data(self, split_ratio=0.2):\n",
    "        test_size = round(split_ratio * len(self.X))\n",
    "        train_size = len(self.X) - test_size\n",
    "        return random_split(self, [train_size, test_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "class ThyroidMLP(Module):\n",
    "    def __init__(self, n_inputs):\n",
    "        super(ThyroidMLP, self).__init__()\n",
    "        # First hidden layer\n",
    "        self.hidden1 = Linear(n_inputs, 10)\n",
    "        kaiming_uniform_(self.hidden1.weight, nonlinearity='relu')\n",
    "        self.act1 = ReLU()\n",
    "        # Second hidden layer\n",
    "        self.hidden2 = Linear(10, 8)\n",
    "        kaiming_uniform_(self.hidden2.weight, nonlinearity='relu')\n",
    "        self.act2 = ReLU()\n",
    "        # Third hidden layer\n",
    "        self.hidden3 = Linear(8,1)\n",
    "        xavier_uniform_(self.hidden3.weight)\n",
    "        self.act3 = Sigmoid()\n",
    "\n",
    "    def forward(self, X):\n",
    "        #Input to the first hidden layer\n",
    "        X = self.hidden1(X)\n",
    "        X = self.act1(X)\n",
    "        # Second hidden layer\n",
    "        X = self.hidden2(X)\n",
    "        X = self.act2(X)\n",
    "        # Third hidden layer\n",
    "        X = self.hidden3(X)\n",
    "        X = self.act3(X)\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_thyroid_dataset(path):\n",
    "    dataset = ThryoidCSVDataset(path)\n",
    "    train, test = dataset.split_data(split_ratio=0.1)\n",
    "    # Prepare data loaders\n",
    "    train_dl = DataLoader(train, batch_size=32, shuffle=True)\n",
    "    test_dl = DataLoader(test, batch_size=1024, shuffle=False)\n",
    "    return train_dl, test_dl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training loop based off our custom class\n",
    "def train_model(train_dl, model):\n",
    "    # Define your optimisation function for reducing loss when weights are calculated \n",
    "    # and propogated through the network\n",
    "    criterion = BCELoss()\n",
    "    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    for epoch in range(100):\n",
    "        # Create batches\n",
    "        for i, (inputs, targets) in enumerate(train_dl):\n",
    "            #Important to clear the gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Compute the model output\n",
    "            yhat = model(inputs)\n",
    "            # Calculate the loss method\n",
    "            loss = criterion(yhat, targets)\n",
    "            # Update model weights through back propogation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "def evaluate_model(test_dl, model):\n",
    "    preds = []\n",
    "    actuals = []\n",
    "\n",
    "    for (i, (inputs, targets)) in tqdm(enumerate(test_dl)):\n",
    "        #Evaluate the model on the test set\n",
    "        yhat = model(inputs)\n",
    "        #Retrieve a numpy weights array\n",
    "        yhat = yhat.detach().numpy()\n",
    "        # Extract the weights using detach to get the numerical values in an ndarray, instead of tensor\n",
    "        #https://www.tutorialspoint.com/how-to-convert-a-pytorch-tensor-with-gradient-to-a-numpy-array\n",
    "        actual = targets.numpy()\n",
    "        actual = actual.reshape((len(actual), 1))\n",
    "        # Round to get the class value i.e. sick vs not sick\n",
    "        yhat = yhat.round()\n",
    "        # Store the predictions in the empty lists initialised at the start of the class\n",
    "        preds.append(yhat)\n",
    "        actuals.append(actual)\n",
    "    \n",
    "    # Stack the predictions and actual arrays vertically\n",
    "    preds, actuals = vstack(preds), vstack(actuals)\n",
    "    #Calculate metrics\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(actuals, preds),\n",
    "        'AU_ROC': roc_auc_score(actuals, preds)\n",
    "    }\n",
    "    return metrics, preds, actuals\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prediction routine\n",
    "def predict(row, model):\n",
    "    row = Tensor([row])\n",
    "    yhat = model(row)\n",
    "    # Get numpy array\n",
    "    yhat = yhat.detach().numpy()\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, test_dl = prepare_thyroid_dataset('data/final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2476 275\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dl.dataset), len(test_dl.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (32x26 and 34x10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/gary_hutson/git_environment/PyTorch_Tutorials/01_MLP_Thyroid_Classifier/thyroid_PyTorch_mlp_new.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.220.0.171/home/gary_hutson/git_environment/PyTorch_Tutorials/01_MLP_Thyroid_Classifier/thyroid_PyTorch_mlp_new.ipynb#ch0000013vscode-remote?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m ThyroidMLP(\u001b[39m34\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.220.0.171/home/gary_hutson/git_environment/PyTorch_Tutorials/01_MLP_Thyroid_Classifier/thyroid_PyTorch_mlp_new.ipynb#ch0000013vscode-remote?line=1'>2</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.220.0.171/home/gary_hutson/git_environment/PyTorch_Tutorials/01_MLP_Thyroid_Classifier/thyroid_PyTorch_mlp_new.ipynb#ch0000013vscode-remote?line=2'>3</a>\u001b[0m train_model(train_dl, model)\n",
      "\u001b[1;32m/home/gary_hutson/git_environment/PyTorch_Tutorials/01_MLP_Thyroid_Classifier/thyroid_PyTorch_mlp_new.ipynb Cell 6'\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_dl, model)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.220.0.171/home/gary_hutson/git_environment/PyTorch_Tutorials/01_MLP_Thyroid_Classifier/thyroid_PyTorch_mlp_new.ipynb#ch0000005vscode-remote?line=10'>11</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.220.0.171/home/gary_hutson/git_environment/PyTorch_Tutorials/01_MLP_Thyroid_Classifier/thyroid_PyTorch_mlp_new.ipynb#ch0000005vscode-remote?line=11'>12</a>\u001b[0m \u001b[39m# Compute the model output\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.220.0.171/home/gary_hutson/git_environment/PyTorch_Tutorials/01_MLP_Thyroid_Classifier/thyroid_PyTorch_mlp_new.ipynb#ch0000005vscode-remote?line=12'>13</a>\u001b[0m yhat \u001b[39m=\u001b[39m model(inputs)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.220.0.171/home/gary_hutson/git_environment/PyTorch_Tutorials/01_MLP_Thyroid_Classifier/thyroid_PyTorch_mlp_new.ipynb#ch0000005vscode-remote?line=13'>14</a>\u001b[0m \u001b[39m# Calculate the loss method\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.220.0.171/home/gary_hutson/git_environment/PyTorch_Tutorials/01_MLP_Thyroid_Classifier/thyroid_PyTorch_mlp_new.ipynb#ch0000005vscode-remote?line=14'>15</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(yhat, targets)\n",
      "File \u001b[0;32m~/anaconda3/envs/transformers-robots/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/gary_hutson/anaconda3/envs/transformers-robots/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/gary_hutson/anaconda3/envs/transformers-robots/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/gary_hutson/anaconda3/envs/transformers-robots/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/gary_hutson/anaconda3/envs/transformers-robots/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/gary_hutson/anaconda3/envs/transformers-robots/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/gary_hutson/anaconda3/envs/transformers-robots/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/gary_hutson/anaconda3/envs/transformers-robots/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/gary_hutson/git_environment/PyTorch_Tutorials/01_MLP_Thyroid_Classifier/thyroid_PyTorch_mlp_new.ipynb Cell 4'\u001b[0m in \u001b[0;36mThyroidMLP.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.220.0.171/home/gary_hutson/git_environment/PyTorch_Tutorials/01_MLP_Thyroid_Classifier/thyroid_PyTorch_mlp_new.ipynb#ch0000003vscode-remote?line=17'>18</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.220.0.171/home/gary_hutson/git_environment/PyTorch_Tutorials/01_MLP_Thyroid_Classifier/thyroid_PyTorch_mlp_new.ipynb#ch0000003vscode-remote?line=18'>19</a>\u001b[0m     \u001b[39m#Input to the first hidden layer\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.220.0.171/home/gary_hutson/git_environment/PyTorch_Tutorials/01_MLP_Thyroid_Classifier/thyroid_PyTorch_mlp_new.ipynb#ch0000003vscode-remote?line=19'>20</a>\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhidden1(X)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.220.0.171/home/gary_hutson/git_environment/PyTorch_Tutorials/01_MLP_Thyroid_Classifier/thyroid_PyTorch_mlp_new.ipynb#ch0000003vscode-remote?line=20'>21</a>\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact1(X)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.220.0.171/home/gary_hutson/git_environment/PyTorch_Tutorials/01_MLP_Thyroid_Classifier/thyroid_PyTorch_mlp_new.ipynb#ch0000003vscode-remote?line=21'>22</a>\u001b[0m     \u001b[39m# Second hidden layer\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/transformers-robots/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/gary_hutson/anaconda3/envs/transformers-robots/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/gary_hutson/anaconda3/envs/transformers-robots/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/gary_hutson/anaconda3/envs/transformers-robots/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/gary_hutson/anaconda3/envs/transformers-robots/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/gary_hutson/anaconda3/envs/transformers-robots/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/gary_hutson/anaconda3/envs/transformers-robots/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/gary_hutson/anaconda3/envs/transformers-robots/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/transformers-robots/lib/python3.8/site-packages/torch/nn/modules/linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///home/gary_hutson/anaconda3/envs/transformers-robots/lib/python3.8/site-packages/torch/nn/modules/linear.py?line=101'>102</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///home/gary_hutson/anaconda3/envs/transformers-robots/lib/python3.8/site-packages/torch/nn/modules/linear.py?line=102'>103</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x26 and 34x10)"
     ]
    }
   ],
   "source": [
    "model = ThyroidMLP(34)\n",
    "# Train the model\n",
    "train_model(train_dl, model)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "92c9f56e7a4fd721f9baef38bcdf25b30d0e78c89f6fb2c3207e6b27a13e62be"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('transformers-robots')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
