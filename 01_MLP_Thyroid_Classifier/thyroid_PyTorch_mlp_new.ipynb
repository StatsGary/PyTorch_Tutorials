{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import vstack\n",
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, average_precision_score\n",
    "from sklearn.metrics import confusion_matrix, recall_score, f1_score\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Sigmoid\n",
    "from torch.nn import Module\n",
    "from torch.optim import SGD\n",
    "from torch.nn import BCELoss\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "from torch.nn.init import xavier_uniform_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original Thyroid data frame contains 27 columns\n",
      "The thyroid X data frame contains 26 columns\n"
     ]
    }
   ],
   "source": [
    "\n",
    "thyroid = pd.read_csv('data/thyroid_new.csv').drop('ID', axis=1)\n",
    "NUM_INPUTS = len(thyroid.columns)\n",
    "print(f'The original Thyroid data frame contains {len(thyroid.columns)} columns')\n",
    "y_label = thyroid['ThryroidClass'] \n",
    "# Preprocess and get rid of na\n",
    "thyroid = thyroid.dropna()\n",
    "\n",
    "# Scale X data\n",
    "X = thyroid.drop('ThryroidClass', axis=1)\n",
    "\n",
    "#thyroid.ThryroidClass\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = pd.DataFrame(scaler.transform(X))\n",
    "print(f'The thyroid X data frame contains {len(X.columns)} columns')\n",
    "Y = pd.Series(y_label)\n",
    "thyroid = pd.concat([X,Y], axis=1)\n",
    "thyroid = thyroid.dropna()\n",
    "thyroid.to_csv('thyroid_raw.csv', header=None, index=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom CSVDataset loader\n",
    "# https://machinelearningmastery.com/pytorch-tutorial-develop-deep-learning-models/\n",
    "class ThryoidCSVDataset(Dataset):\n",
    "    #Constructor for initially loading\n",
    "    def __init__(self,path):\n",
    "        df = read_csv(path, header=None)\n",
    "        # Store the inputs and outputs\n",
    "        self.X = df.values[:, :-1]\n",
    "        self.y = df.values[:, -1] #Assuming your outcome variable is in the first column\n",
    "        self.X = self.X.astype('float32')\n",
    "        # Label encode the target as values 1 and 0 or sick and not sick\n",
    "        self.y = LabelEncoder().fit_transform(self.y)\n",
    "        self.y = self.y.astype('float32')\n",
    "        self.y = self.y.reshape((len(self.y), 1))\n",
    "\n",
    "    # Get the number of rows in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    # Get a row at an index\n",
    "    def __getitem__(self,idx):\n",
    "        return [self.X[idx], self.y[idx]]\n",
    "\n",
    "    # Create custom class method - instead of dunder methods\n",
    "    def split_data(self, split_ratio=0.2):\n",
    "        test_size = round(split_ratio * len(self.X))\n",
    "        train_size = len(self.X) - test_size\n",
    "        return random_split(self, [train_size, test_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "class ThyroidMLP(Module):\n",
    "    def __init__(self, n_inputs):\n",
    "        super(ThyroidMLP, self).__init__()\n",
    "        # First hidden layer\n",
    "        self.hidden1 = Linear(n_inputs, 10)\n",
    "        kaiming_uniform_(self.hidden1.weight, nonlinearity='relu')\n",
    "        self.act1 = ReLU()\n",
    "        # Second hidden layer\n",
    "        self.hidden2 = Linear(10, 8)\n",
    "        kaiming_uniform_(self.hidden2.weight, nonlinearity='relu')\n",
    "        self.act2 = ReLU()\n",
    "        # Third hidden layer\n",
    "        self.hidden3 = Linear(8,1)\n",
    "        xavier_uniform_(self.hidden3.weight)\n",
    "        self.act3 = Sigmoid()\n",
    "\n",
    "    def forward(self, X):\n",
    "        #Input to the first hidden layer\n",
    "        X = self.hidden1(X)\n",
    "        X = self.act1(X)\n",
    "        # Second hidden layer\n",
    "        X = self.hidden2(X)\n",
    "        X = self.act2(X)\n",
    "        # Third hidden layer\n",
    "        X = self.hidden3(X)\n",
    "        X = self.act3(X)\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_thyroid_dataset(path):\n",
    "    dataset = ThryoidCSVDataset(path)\n",
    "    train, test = dataset.split_data(split_ratio=0.1)\n",
    "    # Prepare data loaders\n",
    "    train_dl = DataLoader(train, batch_size=32, shuffle=True)\n",
    "    test_dl = DataLoader(test, batch_size=1024, shuffle=False)\n",
    "    return train_dl, test_dl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training loop based off our custom class\n",
    "def train_model(train_dl, model):\n",
    "    # Define your optimisation function for reducing loss when weights are calculated \n",
    "    # and propogated through the network\n",
    "    criterion = BCELoss()\n",
    "    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    for epoch in range(100):\n",
    "        # Create batches\n",
    "        for i, (inputs, targets) in enumerate(train_dl):\n",
    "            #Important to clear the gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Compute the model output\n",
    "            yhat = model(inputs)\n",
    "            # Calculate the loss method\n",
    "            loss = criterion(yhat, targets)\n",
    "            # Update model weights through back propogation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "def evaluate_model(test_dl, model, beta=1.0):\n",
    "    preds = []\n",
    "    actuals = []\n",
    "\n",
    "    for (i, (inputs, targets)) in enumerate(test_dl):\n",
    "        #Evaluate the model on the test set\n",
    "        yhat = model(inputs)\n",
    "        #Retrieve a numpy weights array\n",
    "        yhat = yhat.detach().numpy()\n",
    "        # Extract the weights using detach to get the numerical values in an ndarray, instead of tensor\n",
    "        #https://www.tutorialspoint.com/how-to-convert-a-pytorch-tensor-with-gradient-to-a-numpy-array\n",
    "        actual = targets.numpy()\n",
    "        actual = actual.reshape((len(actual), 1))\n",
    "        # Round to get the class value i.e. sick vs not sick\n",
    "        yhat = yhat.round()\n",
    "        # Store the predictions in the empty lists initialised at the start of the class\n",
    "        preds.append(yhat)\n",
    "        actuals.append(actual)\n",
    "    \n",
    "    # Stack the predictions and actual arrays vertically\n",
    "    preds, actuals = vstack(preds), vstack(actuals)\n",
    "    #Calculate metrics\n",
    "    cm = confusion_matrix(actuals, preds)\n",
    "    # Get descriptions of tp, tn, fp, fn\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(actuals, preds),\n",
    "        'AU_ROC': roc_auc_score(actuals, preds),\n",
    "        'precision': precision_score(actuals, preds),\n",
    "        'recall': recall_score(actuals, preds),\n",
    "        'f1_score': f1_score(actuals, preds),\n",
    "        'average_precision_score': average_precision_score(actuals, preds),\n",
    "        'f_beta': ((1+beta**2) * precision_score(actuals, preds) * recall_score(actuals, preds)) / (beta**2 * precision_score(actuals, preds) + recall_score(actuals, preds)),\n",
    "        'confusion_matrix': confusion_matrix(actuals, preds), \n",
    "        'TP': tp,\n",
    "        'FP': fp, \n",
    "        'FN': fn, \n",
    "        'TN': tn\n",
    "    }\n",
    "    return metrics, preds, actuals\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prediction routine\n",
    "def predict(row, model):\n",
    "    row = Tensor([row])\n",
    "    yhat = model(row)\n",
    "    # Get numpy array\n",
    "    yhat = yhat.detach().numpy()\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, test_dl = prepare_thyroid_dataset('https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316 35\n",
      "<torch.utils.data.dataset.Subset object at 0x7f25b0bb4eb0>\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dl.dataset), len(test_dl.dataset))\n",
    "print(train_dl.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 2 0 24\n",
      "0.9230769230769231\n",
      "0.9230769230769231\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Specify the number of input dimensions\n",
    "model = ThyroidMLP(34)\n",
    "# Train the model\n",
    "train_model(train_dl, model)\n",
    "# Evaluate the model\n",
    "results = evaluate_model(test_dl, model)[0]\n",
    "cm = results['confusion_matrix']\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "\n",
    "precision_manual = tp / (tp + fp)\n",
    "recall_manual = tp / (tp + fn)\n",
    "print(precision_manual)\n",
    "print(results['precision'])\n",
    "\n",
    "print(recall_manual)\n",
    "print(results['recall'])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "92c9f56e7a4fd721f9baef38bcdf25b30d0e78c89f6fb2c3207e6b27a13e62be"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('transformers-robots')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
